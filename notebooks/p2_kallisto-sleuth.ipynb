{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:31.436656Z",
     "start_time": "2020-04-30T19:14:31.128847Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make TPM matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:31.455823Z",
     "start_time": "2020-04-30T19:14:31.439140Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = pd.read_csv(\"../data/intermediate/experiment_setup.txt\", sep=\"\\t\")\n",
    "\n",
    "experiments[\"kallisto_path\"] = (\n",
    "    \"../data/intermediate/kallisto_quant/\" + experiments[\"sample\"] + \"/abundance.tsv\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_tpms(exp_path, exp_name):\n",
    "    abundances = pd.read_csv(exp_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    tpms = abundances[\"tpm\"]\n",
    "    tpms = tpms.rename(exp_name)\n",
    "    tpms = tpms.astype(np.float64)\n",
    "\n",
    "    return tpms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge transcript TPMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:48.134990Z",
     "start_time": "2020-04-30T19:14:31.458569Z"
    }
   },
   "outputs": [],
   "source": [
    "exps = zip(experiments[\"kallisto_path\"], experiments[\"sample\"])\n",
    "\n",
    "# read in TPMs for each experiment\n",
    "transcript_tpms = [load_tpms(x[0], x[1]) for x in exps]\n",
    "transcript_tpms = pd.concat(transcript_tpms, axis=1)\n",
    "\n",
    "transcript_tpms.to_csv(\"../data/processed/transcript_tpms.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge gene TPMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:50.761389Z",
     "start_time": "2020-04-30T19:14:48.136800Z"
    }
   },
   "outputs": [],
   "source": [
    "t2g = pd.read_csv(\"../data/intermediate/sleuth_diff/ensembl_t2g.csv\")\n",
    "\n",
    "_, align_ensembl_genes = transcript_tpms.align(\n",
    "    t2g.set_index(\"target_id\")[\"ens_gene\"], axis=0, join=\"inner\"\n",
    ")\n",
    "\n",
    "# group transcripts by gene and sum\n",
    "gene_tpms = transcript_tpms.groupby(align_ensembl_genes).sum()\n",
    "\n",
    "gene_tpms.to_csv(\"../data/processed/gene_tpms.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleuth outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:50.766634Z",
     "start_time": "2020-04-30T19:14:50.763204Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"experiments.json\", \"r\") as f:\n",
    "    exp = json.load(f)\n",
    "\n",
    "    experiments = exp[\"experiments\"]\n",
    "    experiment_ids = exp[\"experiment_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:50.779501Z",
     "start_time": "2020-04-30T19:14:50.768001Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_medians(sleuth_diff, experiment):\n",
    "\n",
    "    # compute the medians in control/treatment groups\n",
    "    sleuth_diff[\"control_median\"] = sleuth_diff[experiments[experiment][0]].median(\n",
    "        axis=1\n",
    "    )\n",
    "    sleuth_diff[\"treatment_median\"] = sleuth_diff[experiments[experiment][1]].median(\n",
    "        axis=1\n",
    "    )\n",
    "    sleuth_diff[\"median_foldchange\"] = (\n",
    "        sleuth_diff[\"treatment_median\"] / sleuth_diff[\"control_median\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def signed_p_rank(sleuth_diff):\n",
    "\n",
    "    # compute -log10 P-values\n",
    "    sleuth_diff[\"-log_pval\"] = -np.log10(sleuth_diff[\"pval\"])\n",
    "\n",
    "    # replace ultra-low P-values\n",
    "    sleuth_diff[\"-log_pval\"] = sleuth_diff[\"-log_pval\"].replace(np.inf, 320)\n",
    "\n",
    "    sleuth_diff[\"treatment_increase\"] = -1 + 2 * (sleuth_diff[\"median_foldchange\"] > 1)\n",
    "\n",
    "    sleuth_diff[\"signed_pval\"] = (\n",
    "        sleuth_diff[\"-log_pval\"] * sleuth_diff[\"treatment_increase\"]\n",
    "    )\n",
    "\n",
    "    sleuth_diff = sleuth_diff.sort_values(by=\"signed_pval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:50.788165Z",
     "start_time": "2020-04-30T19:14:50.782640Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_sleuth_transcripts(experiment):\n",
    "    sleuth_diff = pd.read_csv(\n",
    "        \"../data/intermediate/sleuth_diff/\" + experiment + \"_transcripts.csv\",\n",
    "        index_col=1,\n",
    "    )\n",
    "\n",
    "    controls = experiments[experiment][0]\n",
    "    treatments = experiments[experiment][1]\n",
    "\n",
    "    sleuth_tpms = transcript_tpms.loc[sleuth_diff.index, controls + treatments]\n",
    "\n",
    "    sleuth_diff = pd.concat([sleuth_diff, sleuth_tpms], axis=1)\n",
    "\n",
    "    # compute medians and P-values\n",
    "    compute_medians(sleuth_diff, experiment)\n",
    "    signed_p_rank(sleuth_diff)\n",
    "\n",
    "    # remove missing values\n",
    "    sleuth_diff = sleuth_diff.dropna(\n",
    "        subset=[\"pval\", \"median_foldchange\", \"entrez_gene\"], how=\"any\"\n",
    "    )\n",
    "\n",
    "    # format Entrez ID as string\n",
    "    sleuth_diff[\"entrez_gene\"] = sleuth_diff[\"entrez_gene\"].astype(int).astype(str)\n",
    "\n",
    "    sleuth_diff.to_csv(\n",
    "        \"../data/processed/kallisto_sleuth_merge/\" + experiment + \"_transcripts.txt\",\n",
    "        sep=\"\\t\",\n",
    "    )\n",
    "    sleuth_diff.to_hdf(\n",
    "        \"../data/processed/kallisto_sleuth_merge/\" + experiment + \"_transcripts.h5\",\n",
    "        key=\"sleuth_diff\",\n",
    "        mode=\"w\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:14:50.796633Z",
     "start_time": "2020-04-30T19:14:50.790438Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_sleuth_genes(experiment):\n",
    "    sleuth_diff = pd.read_csv(\n",
    "        \"../data/intermediate/sleuth_diff/\" + experiment + \"_genes.csv\", index_col=1\n",
    "    )\n",
    "\n",
    "    controls = experiments[experiment][0]\n",
    "    treatments = experiments[experiment][1]\n",
    "\n",
    "    sleuth_tpms = gene_tpms.loc[sleuth_diff.index, controls + treatments]\n",
    "\n",
    "    sleuth_diff = pd.concat([sleuth_diff, sleuth_tpms], axis=1)\n",
    "\n",
    "    # compute medians and P-values\n",
    "    compute_medians(sleuth_diff, experiment)\n",
    "    signed_p_rank(sleuth_diff)\n",
    "\n",
    "    # remove missing values\n",
    "    sleuth_diff = sleuth_diff.dropna(\n",
    "        subset=[\"pval\", \"median_foldchange\", \"target_id\"], how=\"any\"\n",
    "    )\n",
    "\n",
    "    # drop biotype column\n",
    "    sleuth_diff = sleuth_diff.drop([\"transcript_biotype\"], axis=1)\n",
    "    sleuth_diff = sleuth_diff[~sleuth_diff.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    # format Entrez ID as string\n",
    "    sleuth_diff[\"target_id\"] = sleuth_diff[\"target_id\"].astype(int).astype(str)\n",
    "\n",
    "    sleuth_diff.to_csv(\n",
    "        \"../data/processed/kallisto_sleuth_merge/\" + experiment + \"_genes.txt\", sep=\"\\t\"\n",
    "    )\n",
    "    sleuth_diff.to_hdf(\n",
    "        \"../data/processed/kallisto_sleuth_merge/\" + experiment + \"_genes.h5\",\n",
    "        key=\"sleuth_diff\",\n",
    "        mode=\"w\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply over experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T19:15:25.214502Z",
     "start_time": "2020-04-30T19:14:50.798499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpl22_oe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khu/anaconda3/envs/cenv/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  import sys\n",
      "/Users/khu/anaconda3/envs/cenv/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1116: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n",
      "/Users/khu/anaconda3/envs/cenv/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log10\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/khu/.local/lib/python3.7/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['hgnc_gene', 'target_id']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "/Users/khu/anaconda3/envs/cenv/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log10\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/khu/.local/lib/python3.7/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['ens_gene', 'hgnc_gene', 'entrez_gene', 'transcript_biotype']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpl22l1_oe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khu/anaconda3/envs/cenv/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  import sys\n",
      "/Users/khu/anaconda3/envs/cenv/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1116: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpl22l1_kd1\n",
      "rpl22l1_kd2\n",
      "rpl22_a_ko1\n",
      "rpl22_a_ko2\n",
      "rpl22_b_ko1\n",
      "rpl22_b_ko2\n"
     ]
    }
   ],
   "source": [
    "for exp_id in experiment_ids:\n",
    "\n",
    "    print(exp_id)\n",
    "\n",
    "    process_sleuth_genes(exp_id)\n",
    "    process_sleuth_transcripts(exp_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
